## 1. Project Overview

We are given historical bike rental data with features such as:

- Date and time of the record
- Season, holiday, working day flags
- Weather, temperature, humidity, windspeed
- Target variable: **`count`** (total number of rentals per hour)

The task is to:

1. Explore and clean the data.
2. Engineer useful features (especially from the `datetime` column).
3. Train and compare several regression models:
   - Baseline (predict mean)
   - Linear Regression
   - Polynomial features + Ridge Regression
   - Polynomial features + Lasso Regression
4. Evaluate models using **RMSE** and **RMSLE**.
5. Choose a “winning” model and generate predictions on the test set in the required `Submission.csv` format.

---

## 2. Repository Structure

```text
.
├── ML_Assignment_1.ipynb      # Main Jupyter notebook with answers to Q1–Q12
├── bike_train.csv             # Training data (provided)
├── bike_test.csv              # Test data (provided)
├── SampleSubmission.csv       # Sample submission format (provided)
├── Submission.csv             # Final predictions generated by my notebook
├── lab_proof.png / .pdf       # Screenshot proof from BITS virtual lab (optional)
└── README.md                  # This file
````

> Note: Only some of these files may be committed publicly (depending on course rules).
> The CSVs listed above are the files used locally to run the notebook.

---

## 3. Environment & Dependencies

This project uses:

* Python 3.8+
* [NumPy](https://numpy.org/)
* [Pandas](https://pandas.pydata.org/)
* [Matplotlib](https://matplotlib.org/)
* [scikit-learn](https://scikit-learn.org/)

### Install dependencies

```bash
pip install numpy pandas matplotlib scikit-learn
```

> On the BITS virtual lab, I had to install scikit-learn inside the notebook using:
>
> ```python
> %pip install scikit-learn
> ```
>
> or select a kernel that already had scikit-learn preinstalled.

---

## 4. How to Run the Notebook Locally

1. Clone this repo and move into the project directory:

   ```bash
   git clone <your-repo-url>
   cd <your-repo-folder>
   ```

2. (Optional) Create a virtual environment and activate it.

3. Install the dependencies:

   ```bash
   pip install -r requirements.txt   # if you create one
   # or manually:
   pip install numpy pandas matplotlib scikit-learn
   ```

4. Launch Jupyter:

   ```bash
   jupyter notebook
   ```

5. Open `ML_Assignment_1.ipynb` and run all cells:

   * **Kernel → Restart & Run All**

The notebook:

* Answers all 12 questions (Q1–Q12) with a mix of code, plots, and Markdown explanations.
* Saves `Submission.csv` in the project directory when the final cell is executed.

---

## 5. Feature Engineering Summary

Key steps applied to both `bike_train.csv` and `bike_test.csv`:

* Parsed `datetime` as a proper datetime type.
* Derived time-based features:

  * `hour` (0–23)
  * `dayofweek` (0–6, Monday–Sunday)
  * `month` (1–12)
  * `year`
  * `is_weekend` (1 if Saturday/Sunday else 0)
* Kept original columns:

  * `season`, `holiday`, `workingday`, `weather`, `temp`, `atemp`, `humidity`, `windspeed`
* Excluded target-related columns (`casual`, `registered`, `count`) from the feature set when training models.

Final feature list used in most models:

```python
feature_cols = [
    'season', 'holiday', 'workingday', 'weather',
    'temp', 'atemp', 'humidity', 'windspeed',
    'hour', 'dayofweek', 'month', 'year', 'is_weekend'
]
```

---

## 6. Models & Evaluation

### Models tried

1. **Baseline (predict mean)**

   * Always predicts the mean `count` from the training data.

2. **Linear Regression**

   * Ordinary least squares on the engineered features above.

3. **Polynomial (degree 2) + Ridge Regression**

   * Generates degree-2 polynomial and interaction features via:

     ```python
     PolynomialFeatures(degree=2, include_bias=False)
     ```
   * Standardizes them with `StandardScaler`.
   * Applies Ridge regression (`L2` regularization) with tuned `alpha`.

4. **Polynomial (degree 2) + Lasso Regression**

   * Same polynomial features and scaling as Ridge.
   * Uses Lasso (`L1` regularization) with tuned `alpha`.

### Metrics

* **RMSE** (Root Mean Squared Error)
* **RMSLE** (Root Mean Squared Logarithmic Error) – main comparison metric in Q7–Q10.

### Example validation results (RMSLE)

These numbers are based on one of my runs; they may vary slightly if you re-run with different splits or seeds:

| Model                           | RMSLE (val) | Notes                                                                  |
| ------------------------------- | ----------- | ---------------------------------------------------------------------- |
| Baseline (predict mean)         | ~1.57       | Naive reference, ignores all features.                                 |
| **Linear Regression**           | **~1.29**   | Best RMSLE; simple linear model on engineered features.                |
| Poly (deg=2) + Ridge (α = 0.01) | ~1.37       | Improves RMSE but worse RMSLE; complex model, more sensitive to noise. |
| Poly (deg=2) + Lasso (α = 0.01) | ~1.37       | Similar to Ridge; performs feature selection via L1 regularization.    |

**Winning model (by RMSLE):**

> Simple **Linear Regression** on the engineered feature set.

---

## 7. Generating `Submission.csv`

The final notebook cell:

1. Reloads `bike_train.csv` and `bike_test.csv`.
2. Reapplies the same datetime feature engineering.
3. Trains a **LinearRegression** model on the **full training data** (`X_full`, `y_full`).
4. Predicts counts for `bike_test.csv`.
5. Clips negatives to 0 and rounds to integers.
6. Writes predictions into a copy of `SampleSubmission.csv`:

```python
sub = pd.read_csv("SampleSubmission.csv")
sub['Count_Predicted'] = y_test_pred
sub.to_csv("Submission.csv", index=False)
```

The resulting file has columns such as:

* `datetime`
* `Count_Predicted`

This `Submission.csv` is what was uploaded to the assignment portal.

---

## 8. Running on BITS Virtual Lab

To satisfy the course requirement, the notebook was also executed on the BITS virtual lab:

* All required files (`ML_Assignment_1.ipynb`, `bike_train.csv`, `bike_test.csv`, `SampleSubmission.csv`) were uploaded to the lab environment.
* In some environments, `scikit-learn` was missing and had to be installed with:

  ```python
  %pip install scikit-learn
  ```


---

## 9. Possible Improvements / Future Work

* Try alternative models (Random Forest, Gradient Boosting, XGBoost).
* Use degree-3 polynomial features with careful regularization.
* Treat time-of-day effects with cyclic encodings (sin/cos of hour).
* Hyperparameter tuning with cross-validation instead of a single train/validation split.
* More advanced feature engineering: e.g., moving averages, holiday types, weather bins.




- Add/remove sections depending on how detailed you want the README to be.
```
